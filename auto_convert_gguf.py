#!/usr/bin/env python3
"""
å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•ã§GGUFå½¢å¼ã«å¤‰æ›ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import sys
import os
import subprocess
from pathlib import Path

def install_llama_cpp():
    """llama.cppã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"""
    try:
        print("=== llama.cppè‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«é–‹å§‹ ===")
        
        # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚¯ãƒ­ãƒ¼ãƒ³
        if not os.path.exists("./llama.cpp"):
            print("llama.cppã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­...")
            subprocess.run([
                "git", "clone", 
                "https://github.com/ggerganov/llama.cpp.git"
            ], check=True, capture_output=True)
            print("âœ… ã‚¯ãƒ­ãƒ¼ãƒ³å®Œäº†")
        else:
            print("âœ… llama.cppãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒæ—¢ã«å­˜åœ¨")
        
        # ãƒ“ãƒ«ãƒ‰
        print("llama.cppã‚’ãƒ“ãƒ«ãƒ‰ä¸­...")
        result = subprocess.run([
            "make", "-C", "./llama.cpp", "-j4"
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… ãƒ“ãƒ«ãƒ‰å®Œäº†")
        else:
            print(f"ãƒ“ãƒ«ãƒ‰è­¦å‘Š/ã‚¨ãƒ©ãƒ¼: {result.stderr}")
        
        # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
        convert_script = "./llama.cpp/convert_hf_to_gguf.py"
        quantize_tool = "./llama.cpp/llama-quantize"
        
        if os.path.exists(convert_script):
            print(f"âœ… å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆç¢ºèª: {convert_script}")
            return convert_script
        else:
            # æ–°ã—ã„ãƒ‘ã‚¹ã‚‚ç¢ºèª
            convert_script = "./llama.cpp/convert.py"
            if os.path.exists(convert_script):
                print(f"âœ… å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆç¢ºèª: {convert_script}")
                return convert_script
            else:
                print("âŒ å¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
    except subprocess.CalledProcessError as e:
        print(f"âŒ llama.cppã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def convert_to_gguf(model_path: str, output_path: str, convert_script: str):
    """ãƒ¢ãƒ‡ãƒ«ã‚’GGUFå½¢å¼ã«å¤‰æ›"""
    try:
        print(f"=== GGUFå¤‰æ›é–‹å§‹ ===")
        print(f"å…¥åŠ›: {model_path}")
        print(f"å‡ºåŠ›: {output_path}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # convert_hf_to_gguf.py ã¾ãŸã¯ convert.py ã‚’ä½¿ç”¨
        if "convert_hf_to_gguf.py" in convert_script:
            cmd = [
                "python3", convert_script,
                model_path,
                "--outdir", os.path.dirname(output_path),
                "--outfile", os.path.basename(output_path)
            ]
        else:
            # æ–°ã—ã„convert.pyã®å ´åˆ
            cmd = [
                "python3", convert_script,
                model_path,
                "--outdir", os.path.dirname(output_path)
            ]
        
        print(f"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
        
        if result.returncode == 0:
            print("âœ… GGUFå¤‰æ›å®Œäº†")
            print(f"stdout: {result.stdout}")
            
            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
            output_dir = os.path.dirname(output_path)
            for file in os.listdir(output_dir):
                if file.endswith('.gguf'):
                    actual_output = os.path.join(output_dir, file)
                    size_mb = os.path.getsize(actual_output) / (1024 * 1024)
                    print(f"å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {actual_output} ({size_mb:.1f} MB)")
                    return actual_output
            
            return output_path if os.path.exists(output_path) else None
        else:
            print(f"âŒ å¤‰æ›ã‚¨ãƒ©ãƒ¼:")
            print(f"stdout: {result.stdout}")
            print(f"stderr: {result.stderr}")
            return None
            
    except subprocess.TimeoutExpired:
        print("âŒ å¤‰æ›ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
        return None
    except Exception as e:
        print(f"âŒ å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return None

def quantize_gguf(gguf_path: str, quantization_type: str = "Q4_K_M"):
    """GGUFãƒ¢ãƒ‡ãƒ«ã‚’é‡å­åŒ–"""
    try:
        print(f"=== GGUFé‡å­åŒ–é–‹å§‹ ({quantization_type}) ===")
        
        # é‡å­åŒ–å¾Œã®ãƒ•ã‚¡ã‚¤ãƒ«å
        base_name = os.path.splitext(gguf_path)[0]
        quantized_path = f"{base_name}-{quantization_type}.gguf"
        
        # llama.cppã®é‡å­åŒ–ãƒ„ãƒ¼ãƒ«
        quantize_tool = "./llama.cpp/llama-quantize"
        
        if not os.path.exists(quantize_tool):
            print("âŒ llama-quantizeãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return gguf_path  # å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¿”ã™
        
        cmd = [
            quantize_tool,
            gguf_path,
            quantized_path,
            quantization_type
        ]
        
        print(f"å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰: {' '.join(cmd)}")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
        
        if result.returncode == 0:
            print("âœ… é‡å­åŒ–å®Œäº†")
            
            if os.path.exists(quantized_path):
                size_mb = os.path.getsize(quantized_path) / (1024 * 1024)
                print(f"é‡å­åŒ–ãƒ•ã‚¡ã‚¤ãƒ«: {quantized_path} ({size_mb:.1f} MB)")
                return quantized_path
            else:
                print("âŒ é‡å­åŒ–ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return gguf_path
        else:
            print(f"é‡å­åŒ–ã‚¨ãƒ©ãƒ¼ï¼ˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰:")
            print(f"stderr: {result.stderr}")
            return gguf_path
            
    except subprocess.TimeoutExpired:
        print("âŒ é‡å­åŒ–ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰")
        return gguf_path
    except Exception as e:
        print(f"é‡å­åŒ–ã‚¨ãƒ©ãƒ¼: {e}ï¼ˆå…ƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼‰")
        return gguf_path

def copy_to_lm_studio(gguf_path: str, model_name: str):
    """GGUFãƒ•ã‚¡ã‚¤ãƒ«ã‚’LM Studioãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼"""
    try:
        import shutil
        
        lm_studio_dir = os.path.expanduser("~/Library/Application Support/lm-studio/models")
        target_dir = os.path.join(lm_studio_dir, model_name)
        
        print(f"=== LM Studioã«ã‚³ãƒ”ãƒ¼ ===")
        print(f"ã‚³ãƒ”ãƒ¼å…ˆ: {target_dir}")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(target_dir, exist_ok=True)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
        target_path = os.path.join(target_dir, os.path.basename(gguf_path))
        shutil.copy2(gguf_path, target_path)
        
        size_mb = os.path.getsize(target_path) / (1024 * 1024)
        print(f"âœ… ã‚³ãƒ”ãƒ¼å®Œäº†: {target_path} ({size_mb:.1f} MB)")
        return target_path
        
    except Exception as e:
        print(f"âŒ ã‚³ãƒ”ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    print("=== è‡ªå‹•GGUFå¤‰æ›ãƒ„ãƒ¼ãƒ« ===")
    
    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
    model_paths = {
        "minimal_test": "./lm_studio_models/minimal_test_merged",
        "GFM": "./lm_studio_models/DialoGPT-small-GFM_merged"
    }
    
    available_models = []
    for name, path in model_paths.items():
        if os.path.exists(path):
            available_models.append((name, path))
        else:
            print(f"ã‚¹ã‚­ãƒƒãƒ—: {name} (ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {path})")
    
    if not available_models:
        print("âŒ å¤‰æ›å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("å…ˆã«merge_for_lmstudio.pyã¾ãŸã¯merge_gfm_model.pyã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    print(f"\nåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«:")
    for i, (name, path) in enumerate(available_models):
        print(f"  {i+1}. {name} ({path})")
    
    # llama.cppã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
    convert_script = install_llama_cpp()
    if not convert_script:
        print("âŒ llama.cppã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # å…¨ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›
    successful_conversions = []
    
    for name, model_path in available_models:
        print(f"\n{'='*60}")
        print(f"=== {name}ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›é–‹å§‹ ===")
        print(f"{'='*60}")
        
        # GGUFå¤‰æ›
        gguf_dir = "./gguf_models"
        gguf_path = os.path.join(gguf_dir, f"{name}.gguf")
        
        converted_path = convert_to_gguf(model_path, gguf_path, convert_script)
        
        if converted_path and os.path.exists(converted_path):
            # é‡å­åŒ–
            quantized_path = quantize_gguf(converted_path, "Q4_K_M")
            
            # LM Studioã«ã‚³ãƒ”ãƒ¼
            lm_studio_path = copy_to_lm_studio(quantized_path, f"{name}-gguf")
            
            if lm_studio_path:
                successful_conversions.append((name, lm_studio_path))
                print(f"âœ… {name}ãƒ¢ãƒ‡ãƒ«ã®GGUFå¤‰æ›å®Œäº†")
            else:
                print(f"âŒ {name}ãƒ¢ãƒ‡ãƒ«ã®LM Studioã‚³ãƒ”ãƒ¼å¤±æ•—")
        else:
            print(f"âŒ {name}ãƒ¢ãƒ‡ãƒ«ã®å¤‰æ›å¤±æ•—")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print(f"=== å¤‰æ›çµæœã‚µãƒãƒªãƒ¼ ===")
    print(f"{'='*60}")
    
    if successful_conversions:
        print(f"âœ… æˆåŠŸã—ãŸå¤‰æ›: {len(successful_conversions)}å€‹")
        for name, path in successful_conversions:
            print(f"  - {name}: {path}")
        
        print(f"\nğŸš€ LM Studioä½¿ç”¨æ–¹æ³•:")
        print(f"1. LM Studioã‚’é–‹ã")
        print(f"2. ä»¥ä¸‹ã®GGUFãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½:")
        for name, _ in successful_conversions:
            print(f"   - {name}-gguf")
        
        print(f"\nğŸ’¡ GGUFå½¢å¼ã®åˆ©ç‚¹:")
        print(f"- ã‚ˆã‚Šé«˜é€Ÿãªæ¨è«–é€Ÿåº¦")
        print(f"- ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å‰Šæ¸›")
        print(f"- CPUæ¨è«–ã®æœ€é©åŒ–")
        print(f"- é‡å­åŒ–ã«ã‚ˆã‚‹å°ã•ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º")
        
    else:
        print(f"âŒ å¤‰æ›ã«æˆåŠŸã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
    
    print(f"\nğŸ‰ GGUFå¤‰æ›å‡¦ç†å®Œäº†ï¼")

if __name__ == "__main__":
    main()